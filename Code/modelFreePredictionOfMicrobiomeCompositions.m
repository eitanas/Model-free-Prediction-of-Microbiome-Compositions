%% Essential code for the paper:
%
%

%% Functions

KLD = @(x,y) sum(x(x>0).*log(x(x>0)./y(x>0)));
rJSD = @(x,y) sqrt(0.5*KLD(x, (x+y)/2) + 0.5*KLD(y,(x+y)/2));

%% variables
CATALOG_SIZES = [10 20:20:200 400 500 1e3 2e3];
NUM_SPECIES = 100;
SIGMA = 0.6;
REALIZATIONS=10;
REALS_PER_SIZE = 100;
%% Interaction matrix
A = rand(NUM_SPECIES,1);
B = sprandn(NUM_SPECIES, NUM_SPECIES, 0.5);
B = B.*SIGMA^2;
B(1:1+size(B,1):end) = -1;
dxdt = @(t,x) A.*x + x.*(B*x);
%%

for cat_si=1:length(CATALOG_SIZES)
   
    dxdt = @(t,x) A.*x + x.*(B*x);
    [t,y] = ode45(dxdt, [0 tmax], y0);

end

%% calculating the recommended abundance:

suggested_abundance = y_ends(:,min_ind);
v_recom = get_recommended_abundance(true_abundance, suggested_abundance, mean_abundance);
res = rJSD(true_abundance, v_recom');

%%

function v = get_recommended_abundance(v1, v2, mean_v )
%                     true_abundance, suggested_abundance, mean_abundance
% suggested_abundance needs to be modified according to the non zero
% indices of real
% v1 = true_abundance;
% v2 = suggested_abundance;
% v is the result vector
v = zeros(1, length(v1));
% indices that I need to take values from "suggested"
nonzero_idxs = intersect(find(v1>0), find(v2>0));
v(nonzero_idxs) = v2(nonzero_idxs);
C = setdiff(find(v1>0), find(v2>0));
% C = setdiff(find(suggested_abundance>0), find(true_abundance>0))
v(C) = mean_v(C);
%idx=find(v==0);

v = v./sum(v);
% calculate distance

%u1=v1;
%u2=v;

%J=sum(u1 ~=0 & u2~=0) / sum(u1~=0 | u2~=0);
end


%% Neural Network:

function net = my_nnfit(num_hidden_neurons, X, y_ends)
% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 03-Mar-2021 16:13:35
%
% This script assumes these variables are defined:
%
%   X - input data.
%   y_ends - target data.

x = X;
t = y_ends;

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.

% Create a Fitting Network
hiddenLayerSize = num_hidden_neurons;
net = fitnet(hiddenLayerSize,trainFcn);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 20/100;
net.divideParam.testRatio = 10/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotregression', 'plotfit'};

% Train the Network
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
e = gsubtract(t,y);
performance = perform(net,t,y);

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y);
valPerformance = perform(net,valTargets,y);
testPerformance = perform(net,testTargets,y);

% View the Network
% view(net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotregression(t,y)
%figure, plotfit(net,x,t)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net);
end

end


%% DOC:


function [dissimilarity,overlap] = DOC(X, diss_type, overlap_type)
% size(X) = [num_species,num_samples];
% Calculates the dissimilarity-overlap curve using the rJSD measure.
%X = y_ends';

KLD = @(x,y) sum(x(x>0).*log(x(x>0)./y(x>0)));
rJSD = @(x,y) sqrt(0.5*KLD(x, (x+y)/2) + 0.5*KLD(y,(x+y)/2));
% check this line for normalization
[~, num_tests] = size(X);
overlap = nan(num_tests*(num_tests-1)/2);
dissimilarity = zeros(num_tests*(num_tests-1)/2);
% X = X./sum(X,1);

for i =1:num_tests - 1
    for j = i+1:num_tests
        % Finding the shared species
        SharedSpecies = find(X(:,i)>0 & X(:,j)>0);
        % Calculating the overlap
        switch overlap_type
            case ''
                overlap(i,j) = 0.5*(sum(X(SharedSpecies,i))+sum(X(SharedSpecies,j)));
            case 'jaccard'
                % v1 = X(SharedSpecies,i); v1=v1(v1~=0);
                % v2 = X(SharedSpecies,i); v2=v2(v2~=0);
                % 1-pdist2(X(:,i)', X(:,j)', 'jaccard')
                
                overlap(i,j)=sum(X(:,i) ~=0 & X(:,j)~=0) / sum(X(:,i)~=0 | X(:,j)~=0);  % jaccard index: 1=similar, 0=very far
                %overlap(i,j) = 1-pdist2(X(:,i)', X(:,j)', 'jaccard');
                %v1=X(:,i)';
                %v2=X(:,j)';
                %pdist2(X(:,i)', X(:,j)', 'jaccard');
                
        end
        if overlap(i,j) ~= 0
            
            % Renormalizing the shared species
            v1 = X(SharedSpecies,i)/sum(X(SharedSpecies,i));
            v2 = X(SharedSpecies,j)/sum(X(SharedSpecies,j));
            % v1 = Xf(SharedSpecies,i);
            % v2 = Xf(SharedSpecies,j);
            
            % Calculating the dissimilarity
            switch diss_type
                case 'euclidean'
                    %  dissimilarity(i,j) = 1 - corr(v1,v2,'Type','Spearman');
                    dissimilarity(i,j) = sqrt(sum((v1-v2).^2));
                case 'rjsd'
                    dissimilarity(i,j) = rJSD (v1,v2);
                    
                case 'spearman'
                    dissimilarity(i,j) = pdist2(v1', v2', 'spearman');
            end
            %           dissimilarity(i,j) = norm(v1 - v2);
            %         if dissimilarity(i,j)<1e-5;
            %             a = 1;
            %         end
        end
    end
end

dissimilarity = dissimilarity(:);
overlap = overlap(:);

indx = find(isnan(overlap));
overlap(indx) = [];
dissimilarity(indx) = [];

end



